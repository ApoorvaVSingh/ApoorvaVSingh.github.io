[{"authors":null,"categories":null,"content":"I am a final year undergraduate student in the Department of Electrical Engineering at the National Institute of Technology, Silchar. I completed my schooling from City Montessori School, Lucknow. I did my second year intern from University of Hyderabad under Prof. Atul Negi. I am deeply fascinated by Machine learning and Deep Learning and the underlying high dimensional mathematical modeling that enables it.\nThe level of generalization and adaptability in deep learning architectures needs to attain a certain level before they can be used as decision-making models instead of prediction models. The introduction of simple perturbations on data distributions can render the best of the deep learning models ineffective. This raises concerns on the wide variety of learning theories that form the core of modern machine and deep learning architectures. My long term vision is to revisit the fundamental theory of deep learning to understand when and why they fail.\n  Check out my CV.\n","date":1610297337,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610297337,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a final year undergraduate student in the Department of Electrical Engineering at the National Institute of Technology, Silchar. I completed my schooling from City Montessori School, Lucknow. I did my second year intern from University of Hyderabad under Prof.","tags":null,"title":"Apoorva Vikram Singh","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://ApoorvaVSingh.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Apoorva Vikram Singh"],"categories":[],"content":" The project explores three different algorithms to recommend K movies provided that the user has already rated some movies. Utilized User-User, Item-Item Collaborative filtration and Matrix Factorization for movie recommendation. The dataset used has been downloaded from Link which contained movies along with ratings according to different users. A web scraping script has been used to scrape about 780 movies from IMDB containing particulars about title, year of release, thumbnail, IMDB rating and Synopsis. Web based application using Heroku by User Based collaborative filtering has been deployed here.  ","date":1610297337,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610297337,"objectID":"76555ae64e1ba1d7be9164ede7bbc820","permalink":"https://ApoorvaVSingh.github.io/project/movie/","publishdate":"2021-01-10T22:18:57+05:30","relpermalink":"/project/movie/","section":"project","summary":"The project explores three different algorithms to recommend K movies provided that user has already rated some movies.","tags":["Collaborative filtration","Matrix Factorization"],"title":"Movie Recommendation","type":"project"},{"authors":["Apoorva Vikram Singh","Divyansha","Anubhav Sachan","Tushar Agarwal"],"categories":[],"content":"  Calculation of Patient Similarity based on Patient Demographic and Case Details extracted from XML annotations in Electronic Health Records (EHR).\n  XSLT used for transforming and extracting annotated data into CSV.\n  An ensemble model consisting of both Word Mover’s Distance (WMD) and General Feature Extraction based on curated list of important sections weighted in the ratio 3:1.\n  ","date":1610296133,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610296133,"objectID":"367833b6bfe4f3f6bc593348a1782a6f","permalink":"https://ApoorvaVSingh.github.io/project/patient/","publishdate":"2021-01-10T21:58:53+05:30","relpermalink":"/project/patient/","section":"project","summary":"Presented in Grand Finale of Smart India Hackathon 2019 organized by Ministry of Human Resource Development, India","tags":["Similarity","Joint Learning","Word2Vec","Word Mover’s Distance"],"title":"Patient Case Similarity","type":"project"},{"authors":["Thoudam Doren Singh"," Divyansha","Apoorva Vikram Singh","Abdullah Faiz Ur Rahman Khilji"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610289843,"objectID":"1cbf43f3fa61342ca704528ed97f546b","permalink":"https://ApoorvaVSingh.github.io/publication/singh-2020-hybrid/","publishdate":"2021-01-10T14:46:58.124472Z","relpermalink":"/publication/singh-2020-hybrid/","section":"publication","summary":"Text classification has become a key operation in various natural language processing tasks. The efficiency of most classification algorithms predominantly confide in the quality of input features. In this work, we propose a novel multi-class text classification technique that harvests features from two distinct feature extraction methods. Firstly, a structured heterogeneous text graph built based on document-word relations and word co-occurrences is leveraged using a Graph Convolution Network (GCN). Secondly, the documents are topic modeled to use the document-topic score as features into the classification model. The concerned graph is constructed using Point-Wise Mutual Information (PMI) between pair of word co-occurrences and Term Frequency-Inverse Document Frequency (TF-IDF) score for words in the documents for word co-occurrences. Experimentation reveals that our text classification model outperforms the existing techniques for five benchmark text classification data sets.","tags":["Graph Convolutional Network","Latent Dirichlet Allocation","Text Classification","Topic Modeling"],"title":"A Hybrid Classification Approach using Topic Modeling and Graph Convolution Networks","type":"publication"},{"authors":["Thoudam Doren Singh","and Divyansha","Apoorva Vikram Singh","Anubhav Sachan","Abdullah Faiz Ur Rahman Khilji"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610295508,"objectID":"f987ee025c4a8636b8996bc5a9f33403","permalink":"https://ApoorvaVSingh.github.io/publication/fakenews/","publishdate":"2021-01-10T16:18:27.671035Z","relpermalink":"/publication/fakenews/","section":"publication","summary":"The exponential growth in fake news and its role in deteriorating general public trust and democratic standards certainly calls for some counter combat approaches. The prediction of chances of news to be fake is deemed to be hard task since most of the deceptive news has its roots in true news. With a minor fabrication in legitimate news, influential fake news can be created that can be used for political, entertainment, or business-related gains. This work provides a novel intuitive approach to exploit data from multiple sources to segregate news into real and fake. To efficiently capture the contextual information present in the data, Bidirectional Encoder Representations from Transformer (BERT) have been deployed. It attempts to further enhance the performance of the deceptive news detection model by incorporating information about the speaker profile and the credibility associated with him/her. A hybrid sequence encoding model has been proposed to harvest the speaker profile and speaker credibility data which makes it useful for prediction. On evaluation over benchmark fake news dataset LIAR, our model outperformed the previous state-of-the-art works. This attests to the fact that the speaker’s profile and credibility play a crucial role in predicting the validity of news.","tags":["Fake News","Text Classification","BERT","LIAR"],"title":"Debunking Fake News by Leveraging Speaker Credibility and BERT Based Model","type":"publication"},{"authors":["Thoudam Doren Singh","Abdullah Faiz Ur Rahman Khilji"," Divyansha","Apoorva Vikram Singh","Surmila Thokchom","Sivaji Bandyopadhyay"," others"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610289843,"objectID":"07a0b268e82eb23482b8675de5ea8f55","permalink":"https://ApoorvaVSingh.github.io/publication/singh-2020-predictive/","publishdate":"2021-01-10T14:46:57.871057Z","relpermalink":"/publication/singh-2020-predictive/","section":"publication","summary":"The command line has always been the most efficient method to interact with UNIX flavor based systems while offering a great deal of flexibility and efficiency as preferred by professionals. Such a system is based on manually inputting commands to instruct the computing machine to carry out tasks as desired. This human-computer interface is quite tedious especially for a beginner. And hence, the command line has not been able to garner an overwhelming reception from new users. Therefore, to improve user-friendliness and to mark a step towards a more intuitive command line system, we propose two predictive approaches that can benefit all kinds of users specially the novice ones by integrating into the command line interface. These methods are based on deep learning based predictions. The first approach is based on the sequence to sequence (Seq2seq) model with joint learning by leveraging continuous representations of a self-curated exhaustive knowledge base (KB) comprising an all-inclusive command description to enhance the embedding employed in the model. The other is based on the attention-based transformer architecture where a pretrained model is employed. This allows the model to dynamically evolve over time making it adaptable to different circumstances by learning as the system is being used. To reinforce our idea, we have experimented with our models on three major publicly available Unix command line datasets and have achieved benchmark results using GLoVe and Word2Vec embeddings. Our finding is that the transformer based framework performs better on two different datasets of the three in our experiment in a semantic deficit scenario like UNIX command line prediction. However, Seq2seq based model outperforms bidirectional encoder representations from transformers (BERT) based model on a larger dataset.","tags":["UNIX Command Line Prediction","Knowledge Base","Sequence Prediction","LSTM","GLoVe","Joint Learning","BERT"],"title":"Predictive approaches for the UNIX command line: curating and exploiting domain knowledge in semantics deficit data","type":"publication"},{"authors":["Thoudam Doren Singh","Abdullah Faiz Ur Rahman Khilji"," Divyansha","Apoorva Vikram Singh","Surmila Thokchom","Sivaji Bandyopadhyay"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610289843,"objectID":"5ae9724a2847eab14202fbf92dc4b33d","permalink":"https://ApoorvaVSingh.github.io/publication/singh-2020-seq-2-seq/","publishdate":"2021-01-10T14:46:58.302293Z","relpermalink":"/publication/singh-2020-seq-2-seq/","section":"publication","summary":"Despite being an open-source operating system pioneered in the early 90s, UNIX based platforms have not been able to garner an overwhelming reception from amateur end users. One of the rationales for under popularity of UNIX based systems is the steep learning curve corresponding to them due to extensive use of command line interface instead of usual interactive graphical user interface. In past years, the majority of insights used to explore the concern are eminently centered around the notion of utilizing chronic log history of the user to make the prediction of successive command. The approaches directed at anatomization of this notion are predominantly in accordance with Probabilistic inference models. The techniques employed in past, however, have not been competent enough to address the predicament as legitimately as anticipated. Instead of deploying usual mechanism of recommendation systems, we have employed a simple yet novel approach of Seq2seq model by leveraging continuous representations of self-curated exhaustive Knowledge Base (KB) to enhance the embedding employed in the model. This work describes an assistive, adaptive and dynamic way of enhancing UNIX command line prediction systems. Experimental methods state that our model has achieved accuracy surpassing mixture of other techniques and adaptive command line interface mechanism as acclaimed in the past.","tags":["UNIX Command Line Prediction","Knowledge Base","Sequence Prediction","LSTM","GLoVe","Joint Learning"],"title":"Seq2Seq and Joint Learning Based Unix Command Line Prediction System","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://ApoorvaVSingh.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Apoorva Vikram Singh","Atul Negi"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610289844,"objectID":"9116ad417a6c45d94e46d5bf80c4539f","permalink":"https://ApoorvaVSingh.github.io/publication/singh-2019-towards/","publishdate":"2021-01-10T14:46:58.46682Z","relpermalink":"/publication/singh-2019-towards/","section":"publication","summary":"Drug repositioning offers an economical and efficient alternative to traditional drug discovery. It means that, a drug approved for effect against a particular disease is considered and its applications for novel pharmaceutical purposes are explored in shorter development timelines. Unlike conventional approaches, this work attempts to explore the network of existing drugs and its unmapped indications by treating drug reposi- tioning as a classification problem. The proposed classification model attempts estimation of the relevance of a drug with an unmapped indication. An enhanced word representation model is used for this purpose by integrating knowledge obtained from a structured biological knowledge graph and medical literature. To harvest the structured biological data, we have leveraged multiple biological ontologies to achieve a formal framework in the form of a semantic knowledge graph. Our novelty lies in that we have exploited knowledge from biological knowledge graph and medical corpora to complement each other. This makes our method competent with well established drug repositioning techniques.","tags":["Drug Repositioning","Machine Learning","Word Embedding","Knowledge Graph","Knowledge Base","Ontology"],"title":"Towards Better Drug Repositioning Using Joint Learning","type":"publication"}]